# Let's create the Python files and structure them as requested by the user.

# First, let's define the directory structure
import os

project_name = "Handwritten-Text-Recognition"
subdirs = ["model", "data/train", "data/test", "scripts"]

# Create project directories
for subdir in subdirs:
    os.makedirs(os.path.join(project_name, subdir), exist_ok=True)

# Let's create the script files
train_script = '''import cv2
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Dense, LSTM, Bidirectional
from tensorflow.keras.models import Model
import tensorflow as tf

char_list = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789"

def load_image(path):
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    return cv2.resize(img, (128, 32))

def preprocess_image(img):
    img = img.astype(np.float32) / 255.0
    img = np.expand_dims(img, axis=-1)
    return img

def text_to_labels(text):
    return [char_list.index(c) for c in text]

def labels_to_text(labels):
    return ''.join([char_list[c] for c in labels])

input_shape = (32, 128, 1)
num_classes = len(char_list) + 1

def build_model(input_shape, num_classes):
    inputs = Input(shape=input_shape)
    x = Conv2D(32, (3, 3), activation='relu')(inputs)
    x = MaxPooling2D(pool_size=(2, 2))(x)
    x = Conv2D(64, (3, 3), activation='relu')(x)
    x = MaxPooling2D(pool_size=(2, 2))(x)
    x = Reshape((-1, x.shape[-1]))(x)
    x = Bidirectional(LSTM(128, return_sequences=True))(x)
    x = Bidirectional(LSTM(128, return_sequences=True))(x)
    outputs = Dense(num_classes, activation='softmax')(x)
    model = Model(inputs, outputs)
    return model

model = build_model(input_shape, num_classes)

def ctc_loss(y_true, y_pred):
    input_length = tf.fill([tf.shape(y_pred)[0]], tf.shape(y_pred)[1])
    label_length = tf.fill([tf.shape(y_true)[0]], tf.shape(y_true)[1])
    return tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)

model.compile(optimizer='adam', loss=ctc_loss)

# Assuming train_images and train_labels are available
# Preprocess images and labels
train_images = np.array([preprocess_image(img) for img in train_images])
train_labels = np.array([text_to_labels(text) for text in train_labels])
train_labels = pad_sequences(train_labels, maxlen=max_seq_len, padding='post')

model.fit(train_images, train_labels, batch_size=32, epochs=100)
model.save('model/handwritten_text_recognition_model.h5')
'''

predict_script = '''import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model

char_list = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789"

def load_image(path):
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    return cv2.resize(img, (128, 32))

def preprocess_image(img):
    img = img.astype(np.float32) / 255.0
    img = np.expand_dims(img, axis=-1)
    return img

def labels_to_text(labels):
    return ''.join([char_list[c] for c in labels])

def beam_search_decoder(predictions, top_k=3):
    # Placeholder for beam search decoder
    return "decoded_text"  # dummy return

def predict(img_path):
    img = preprocess_image(load_image(img_path))
    model = load_model('model/handwritten_text_recognition_model.h5')
    pred = model.predict(np.expand_dims(img, axis=0))
    decoded_text = beam_search_decoder(pred)
    return decoded_text

# Example usage
img_path = 'data/test/sample_image.png'
predicted_text = predict(img_path)
print("Predicted text:", predicted_text)
'''

readme_content = '''
# Handwritten Text Recognition

This project implements a Handwritten Text Recognition (HTR) model using CNN, Bi-directional LSTM, and a Beam Search Decoder. The model is capable of recognizing text from images of handwritten documents.

## Setup

1. Install dependencies:

```bash
pip install numpy matplotlib tensorflow keras opencv-python
